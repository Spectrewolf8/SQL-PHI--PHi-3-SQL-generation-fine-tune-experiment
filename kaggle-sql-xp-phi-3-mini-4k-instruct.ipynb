{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install flash_attn==2.5.8\n!pip install torch==2.3.1\n!pip install accelerate==0.31.0\n!pip install transformers==4.41.2\n!pip install datasets\n!pip install transformers\n!pip install trl\n!pip install peft \n!pip install auto-gptq \n!pip install optimum\n!pip install xformers\n!pip install huggingface_hub\n!pip install git+https://github.com/microsoft/LoRA\n    \n#bits and bytes with cuda\n!pip install bitsandbytes-cuda110 bitsandbytes","metadata":{"_uuid":"4d55c2d0-72b2-4fc6-b00d-a2a2fce43fcd","_cell_guid":"b8a7dcd1-aa44-44d7-aebe-d76376affb56","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T16:52:57.137910Z","iopub.execute_input":"2024-07-21T16:52:57.138301Z","iopub.status.idle":"2024-07-21T16:56:11.238686Z","shell.execute_reply.started":"2024-07-21T16:52:57.138270Z","shell.execute_reply":"2024-07-21T16:56:11.237641Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: flash_attn==2.5.8 in /opt/conda/lib/python3.10/site-packages (2.5.8)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash_attn==2.5.8) (2.3.1)\nRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash_attn==2.5.8) (0.8.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash_attn==2.5.8) (21.3)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash_attn==2.5.8) (1.11.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->flash_attn==2.5.8) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn==2.5.8) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash_attn==2.5.8) (12.5.82)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash_attn==2.5.8) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash_attn==2.5.8) (1.3.0)\nRequirement already satisfied: torch==2.3.1 in /opt/conda/lib/python3.10/site-packages (2.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.5.82)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.1) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.1) (1.3.0)\nRequirement already satisfied: accelerate==0.31.0 in /opt/conda/lib/python3.10/site-packages (0.31.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.31.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.31.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.31.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.31.0) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.31.0) (2.3.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.31.0) (0.23.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.31.0) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.31.0) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.31.0) (12.5.82)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.31.0) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.31.0) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.31.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.31.0) (1.3.0)\nRequirement already satisfied: transformers==4.41.2 in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (0.23.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.2) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.41.2) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.41.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.41.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.41.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.41.2) (2024.7.4)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: trl in /opt/conda/lib/python3.10/site-packages (0.9.6)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.3.1)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.41.2)\nRequirement already satisfied: numpy<2.0.0,>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.31.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (2.20.0)\nRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl) (0.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.5.82)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.23.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.66.4)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\nRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (1.7.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.11.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.3.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.41.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.31.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: auto-gptq in /opt/conda/lib/python3.10/site-packages (0.7.1)\nRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.31.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.20.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.26.4)\nRequirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.0.1)\nRequirement already satisfied: gekko in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.2.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.3.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.4.3)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.41.2)\nRequirement already satisfied: peft>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.11.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.66.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto-gptq) (12.5.82)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (0.19.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.9.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.26.0->auto-gptq) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2023.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\nRequirement already satisfied: optimum in /opt/conda/lib/python3.10/site-packages (1.21.2)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum) (15.0.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.13.0)\nRequirement already satisfied: transformers<4.43.0,>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (4.41.2)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.3.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum) (21.3)\nRequirement already satisfied: numpy<2.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (1.26.4)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (0.23.4)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum) (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.5.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->optimum) (3.1.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum) (12.5.82)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.43.0,>=4.26.0->transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<4.43.0,>=4.26.0->transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<4.43.0,>=4.26.0->transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (0.4.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (0.2.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (3.20.3)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.9.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\nRequirement already satisfied: xformers in /opt/conda/lib/python3.10/site-packages (0.0.27)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers) (1.26.4)\nRequirement already satisfied: torch==2.3.1 in /opt/conda/lib/python3.10/site-packages (from xformers) (2.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->xformers) (12.5.82)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.1->xformers) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.1->xformers) (1.3.0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\nCollecting git+https://github.com/microsoft/LoRA\n  Cloning https://github.com/microsoft/LoRA to /tmp/pip-req-build-c3yp98tv\n  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/LoRA /tmp/pip-req-build-c3yp98tv\n  Resolved https://github.com/microsoft/LoRA to commit 4c0333854cb905966f8cc4e9a74068c1e507c7b7\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: bitsandbytes-cuda110 in /opt/conda/lib/python3.10/site-packages (0.26.0.post2)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.82)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Important: You must restart the kernel at this point after installing the packages!!\n`This notebook is written and targetted towards kaggle`\n\n---","metadata":{"_uuid":"a933ad58-25a7-4b8f-90ae-7f6aedca5231","_cell_guid":"56b40174-8d43-432e-a6e8-1b45c4f41aa6","trusted":true}},{"cell_type":"markdown","source":"# Preparing datasets, loading model and tokenizer, Training model \n### Model used: microsoft/Phi-3-mini-4k-instruct","metadata":{"_uuid":"5e4648e6-add2-46bb-bfae-08d491ae2488","_cell_guid":"d1f04aad-873d-4936-aad5-f8f01b4bd74b","trusted":true}},{"cell_type":"code","source":"#load tokens\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\n#logging into Hugging Face\n!huggingface-cli login --token $hf_token","metadata":{"_uuid":"58d11453-8740-483c-b03c-fa0f16655c6a","_cell_guid":"d3f931aa-165a-424f-96e1-0d78ee0aba12","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:00.842920Z","iopub.execute_input":"2024-07-21T17:01:00.843597Z","iopub.status.idle":"2024-07-21T17:01:02.685917Z","shell.execute_reply.started":"2024-07-21T17:01:00.843561Z","shell.execute_reply":"2024-07-21T17:01:02.684780Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# impoting classes\nfrom random import randrange\n\nimport torch\nfrom datasets import load_dataset\n\nfrom peft import LoraConfig, prepare_model_for_kbit_training, PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    set_seed,\n    pipeline\n)\nfrom trl import SFTTrainer","metadata":{"_uuid":"9a275092-7607-4cf1-99f2-65e59bfb087a","_cell_guid":"127a0214-0fab-4775-b206-4bccf2acc09a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:02.688327Z","iopub.execute_input":"2024-07-21T17:01:02.688679Z","iopub.status.idle":"2024-07-21T17:01:02.694714Z","shell.execute_reply.started":"2024-07-21T17:01:02.688647Z","shell.execute_reply":"2024-07-21T17:01:02.693850Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Preparing datasets\n\n# DATASET_NAME is a string that specifies the name of the dataset to be used for fine-tuning.\nDATASET_NAME = synthetic_text_to_sql_dataset_name = \"gretelai/synthetic_text_to_sql\"\n\n# Load the dataset specified by DATASET_NAME using the load_dataset function.\ndataset = load_dataset(DATASET_NAME)\n\ndataset\n\n# Extract relevant fields\n\n# old\n# def extract_fields_synthetic(example):\n#     return {\n#         \"question\": example[\"sql_prompt\"],\n#         \"context\": example[\"sql_context\"],\n#         \"sql\": example[\"sql\"]\n#     }\n\n# new\ndef extract_fields_synthetic(example):\n    return {\n        \"instruction\": example[\"sql_prompt\"],\n        \"input\": example[\"sql_context\"],\n        \"output\": example[\"sql\"]\n    }\nsynthetic_extracted_dataset = dataset.map(extract_fields_synthetic, remove_columns=dataset['train'].column_names)","metadata":{"_uuid":"e81cad84-660b-403c-be37-ef7bb674d9cf","_cell_guid":"d8cce8bc-958b-43a8-9243-ce7384004270","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:02.695901Z","iopub.execute_input":"2024-07-21T17:01:02.696166Z","iopub.status.idle":"2024-07-21T17:01:03.617020Z","shell.execute_reply.started":"2024-07-21T17:01:02.696136Z","shell.execute_reply":"2024-07-21T17:01:03.616127Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Split and shuffle datasets\n\nimport random \n\nsynthetic_extracted_train_dataset = synthetic_extracted_dataset[\"train\"]\nsynthetic_extracted_test_dataset = synthetic_extracted_dataset[\"test\"]\n\n# Shuffle the dataset\nsynthetic_extracted_dataset = synthetic_extracted_dataset.shuffle(seed=random.randint(10,99))\nsynthetic_extracted_dataset = synthetic_extracted_dataset.shuffle(seed=random.randint(10,99))\n\nprint(synthetic_extracted_train_dataset)\nprint(synthetic_extracted_test_dataset)","metadata":{"_uuid":"0ed8c885-9d54-41d4-810d-c3f715bedfa1","_cell_guid":"35a44a41-4d7a-4be6-bf11-94017f1db749","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:03.620107Z","iopub.execute_input":"2024-07-21T17:01:03.620626Z","iopub.status.idle":"2024-07-21T17:01:03.741112Z","shell.execute_reply.started":"2024-07-21T17:01:03.620585Z","shell.execute_reply":"2024-07-21T17:01:03.740124Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['instruction', 'input', 'output'],\n    num_rows: 100000\n})\nDataset({\n    features: ['instruction', 'input', 'output'],\n    num_rows: 5851\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"# 'torch.cuda.is_bf16_supported()' is a function that checks if BF16 is supported on the current GPU. BF16 is a data type that uses 16 bits, like float16, but allocates more bits to the exponent, which can result in higher precision.\n# 'attn_implementation' is a variable that will hold the type of attention implementation to be used.\n\nif torch.cuda.is_bf16_supported():\n  compute_dtype = torch.bfloat16\nelse:\n  compute_dtype = torch.float16\n\nattn_implementation = 'eager'\nprint(attn_implementation)\nprint(compute_dtype)","metadata":{"_uuid":"c6651fc7-3838-4b07-a706-c7583feba83d","_cell_guid":"2bcda16f-49eb-44b7-975f-ae6251984f34","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:03.742258Z","iopub.execute_input":"2024-07-21T17:01:03.742542Z","iopub.status.idle":"2024-07-21T17:01:03.748845Z","shell.execute_reply.started":"2024-07-21T17:01:03.742516Z","shell.execute_reply":"2024-07-21T17:01:03.747861Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"eager\ntorch.bfloat16\n","output_type":"stream"}]},{"cell_type":"code","source":"# MODEL_ID is a string that specifies the identifier of the pre-trained model that will be fine-tuned. \nMODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n\n# NEW_MODEL_NAME is a string that specifies the name of the new model after fine-tuning.\nNEW_MODEL_NAME = \"sql-xp-phi-3-mini-4k\"","metadata":{"_uuid":"47b3096d-3b57-4f8d-a2b6-006710509190","_cell_guid":"684cb7a2-c992-4503-b1e6-d229bc954436","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:03.749925Z","iopub.execute_input":"2024-07-21T17:01:03.750187Z","iopub.status.idle":"2024-07-21T17:01:03.766741Z","shell.execute_reply.started":"2024-07-21T17:01:03.750162Z","shell.execute_reply":"2024-07-21T17:01:03.765876Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#load tokenizr to prepare dataset\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\ntokenizer.padding_side = 'right' # to prevent warnings","metadata":{"_uuid":"82fbc585-0a8c-4658-b83a-a35afa6a2aa5","_cell_guid":"9ecd61b8-5a9a-4953-b9d5-0bf007d4afd3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:03.768022Z","iopub.execute_input":"2024-07-21T17:01:03.768335Z","iopub.status.idle":"2024-07-21T17:01:03.927755Z","shell.execute_reply.started":"2024-07-21T17:01:03.768307Z","shell.execute_reply":"2024-07-21T17:01:03.926854Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define methods for creating and formatting messages/prompts for datasets\n# The prompt will contain our instructions, and the context will include the SQL context, such as a table creation SQL command\n\ndef create_message_column(row):\n    \"\"\"\n    Create a message column for a dataset row.\n    Args: row (dict): A dictionary containing 'instruction', 'input', and 'output' keys.\n    Returns: dict: A dictionary with the key 'message' containing a list of messages for user and assistant.\n    \"\"\"\n    message = []\n\n    # Define the user message with prompt and context\n    user = {\"content\": f\"\\n #prompt: {row['instruction']}\\n #context: {row['input']}\", \"role\": \"user\"}\n    message.append(user)\n\n    # Define the assistant's response\n    assistant = {\"content\": f\"{row['output']}\",\"role\": \"assistant\"}\n    message.append(assistant)\n\n    # Return the constructed message\n    return {\"message\": message}\n\ndef format_dataset_with_chat_template(row):\n    \"\"\"\n    Format a dataset row using the chat template for tokenization.\n    Args: row (dict): A dictionary containing the 'message' key.\n    Returns:dict: A dictionary with the key 'text' containing the formatted text.\n    \"\"\"\n    # Apply the chat template to the message and return the formatted text\n    return {\"text\": tokenizer.apply_chat_template(row[\"message\"], add_generation_prompt=False, tokenize=False)}","metadata":{"_uuid":"17449f9f-15df-4b2f-b553-5332f9a69205","_cell_guid":"5384c2e8-d721-472a-9448-caafa88b3b53","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:03.929023Z","iopub.execute_input":"2024-07-21T17:01:03.929320Z","iopub.status.idle":"2024-07-21T17:01:03.936936Z","shell.execute_reply.started":"2024-07-21T17:01:03.929293Z","shell.execute_reply":"2024-07-21T17:01:03.935979Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Apply create_message_column function\nsynthetic_extracted_train_dataset = synthetic_extracted_train_dataset.map(create_message_column)\nsynthetic_extracted_test_dataset = synthetic_extracted_test_dataset.map(create_message_column)\n\n# Format dataset using \nsynthetic_extracted_train_dataset = synthetic_extracted_train_dataset.map(format_dataset_with_chat_template)\nsynthetic_extracted_test_dataset = synthetic_extracted_test_dataset.map(format_dataset_with_chat_template)\n\n# Output the results to verify\nprint(synthetic_extracted_train_dataset)\nprint(synthetic_extracted_test_dataset)","metadata":{"_uuid":"e2463809-8765-4020-b149-9ffcb454b4e1","_cell_guid":"d7abff41-7819-47e7-bad8-f2b445911840","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:03.938256Z","iopub.execute_input":"2024-07-21T17:01:03.938543Z","iopub.status.idle":"2024-07-21T17:01:04.052378Z","shell.execute_reply.started":"2024-07-21T17:01:03.938517Z","shell.execute_reply":"2024-07-21T17:01:04.051359Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['instruction', 'input', 'output', 'message', 'text'],\n    num_rows: 100000\n})\nDataset({\n    features: ['instruction', 'input', 'output', 'message', 'text'],\n    num_rows: 5851\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"#select subsets of datasets\n# 75:25 dataset ratio\n\nsynthetic_extracted_train_dataset = synthetic_extracted_train_dataset.select(range(10000))\nsynthetic_extracted_test_dataset = synthetic_extracted_test_dataset.select(range(3300))","metadata":{"_uuid":"6b097804-6ff8-4e33-b1b4-5b24b5662931","_cell_guid":"e7cd3b76-4f1d-435d-bf30-877dc00d8e3c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:04.056080Z","iopub.execute_input":"2024-07-21T17:01:04.056405Z","iopub.status.idle":"2024-07-21T17:01:04.068719Z","shell.execute_reply.started":"2024-07-21T17:01:04.056376Z","shell.execute_reply":"2024-07-21T17:01:04.067722Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# 'hf_model_repo' is the identifier for the Hugging Face repository where you want to save the fine-tuned model.\nhf_model_repo=\"spectrewolf8/\"+NEW_MODEL_NAME\n\n# Load Model on GPU \n# 'device_map' is set to {\"\": 0}, which means that the entire model will be loaded on GPU 0.\ndevice_map = {\"\": 0}\n\n# Bits and Bytes configuration for the model\n\n# 'load_in_4bit' is a boolean that control if 4bit quantization should be loaded. In this case, it is set to True\n# 'bnb_4bit_compute_dtype' is the data type that should be used for computations with the 4-bit base model. In this case, it is set to 'bfloat16'.\n# 'bnb_4bit_quant_type' is the type of quantization that should be used for the 4-bit base model. In this case, it is set to 'nf4'.\n# 'bnb_4bit_use_double_quant' is a boolean that controls whether nested quantization should be used for the 4-bit base model.\n\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=True,\n)\n\n# LoRA configuration for the model\n\n# 'lora_r' or 'r' is the dimension of the LoRA attention.\n# 'lora_alpha' is the alpha parameter for LoRA scaling.\n# 'lora_dropout' is the dropout probability for LoRA layers.\n# 'target_modules' is a list of the modules that should be targeted by LoRA.\n# peft configuration for the model\n\nlora_r = 16 #16 default\npeft_config = LoraConfig(\n    lora_alpha = 16, #16 default\n    lora_dropout = 0.05, #0.05 default\n    r = lora_r,\n    target_modules=['k_proj', 'q_proj', 'v_proj', 'o_proj', \"gate_proj\", \"down_proj\", \"up_proj\"]\n)","metadata":{"_uuid":"0a30532f-2411-4932-8a18-dcf3e689373b","_cell_guid":"39788e3b-b879-4168-befc-cce20b0c50ed","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:04.070092Z","iopub.execute_input":"2024-07-21T17:01:04.070478Z","iopub.status.idle":"2024-07-21T17:01:04.079880Z","shell.execute_reply.started":"2024-07-21T17:01:04.070432Z","shell.execute_reply":"2024-07-21T17:01:04.078984Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# # 'set_seed(1234)' sets the random seed for reproducibility.\n# set_seed(1234)\n\n# # username is a string that specifies the GitHub username of the person who is fine-tuning the model.\n# # license is a string that specifies the license under which the model is distributed. In this case, it's Apache License 2.0.\n\n# username = \"spectrewolf8\"\n# license = \"apache-2.0\"","metadata":{"_uuid":"dcc3e338-34eb-4506-964a-5ced1907eb89","_cell_guid":"e51bab17-7c7d-4787-b87f-af18f60c0008","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:04.082790Z","iopub.execute_input":"2024-07-21T17:01:04.083197Z","iopub.status.idle":"2024-07-21T17:01:04.089464Z","shell.execute_reply.started":"2024-07-21T17:01:04.083157Z","shell.execute_reply":"2024-07-21T17:01:04.088567Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# 'AutoTokenizer' is a class from the Hugging Face Transformers library that provides a tokenizer for a given pre-trained model.\n# 'from_pretrained' is a method of the 'AutoTokenizer' class that loads a tokenizer from a pre-trained model.\n# 'trust_remote_code=True' is a parameter that allows the execution of remote code when loading the tokenizer.\n# 'add_eos_token=True' is a parameter that adds an end-of-sentence token to the tokenizer.\n# 'use_fast=True' is a parameter that uses the fast version of the tokenizer, if available.\n# 'tokenizer.pad_token = tokenizer.unk_token' sets the padding token of the tokenizer to be the same as the unknown token.\n# 'tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)' sets the ID of the padding token to be the same as the ID of the padding token.\n# 'tokenizer.padding_side = 'left'' sets the side where padding will be added to be the left side.\n# 'BitsAndBytesConfig' is a class that provides a configuration for quantization.\n# 'bnb_config' is a variable that holds the configuration for quantization.\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True, add_eos_token=True, use_fast=True)\ntokenizer.pad_token = tokenizer.unk_token\ntokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\ntokenizer.padding_side = 'left'\n\n# 'AutoModelForCausalLM' is a class from the Hugging Face Transformers library that provides a model for causal language modeling.\n# 'from_pretrained' is a method of the 'AutoModelForCausalLM' class that loads a model from a pre-trained model.\n# 'torch_dtype=compute_dtype' is a parameter that sets the data type of the model to be the same as 'compute_dtype'.\n# 'quantization_config=bnb_config' is a parameter that sets the configuration for quantization to be 'bnb_config'.\n# 'device_map=device_map' is a parameter that sets the device map of the model to be 'device_map'.\n# 'attn_implementation=attn_implementation' is a parameter that sets the type of attention implementation to be 'attn_implementation'.\n# 'model = prepare_model_for_kbit_training(model)' prepares 'model' for k-bit training and assigns the result back to 'model'.\n\nmodel = AutoModelForCausalLM.from_pretrained(\n          MODEL_ID, torch_dtype=compute_dtype, trust_remote_code=True, quantization_config=bnb_config, device_map=device_map,\n          attn_implementation=attn_implementation\n)\nmodel = prepare_model_for_kbit_training(model)\nmodel.gradient_checkpointing_enable()","metadata":{"_uuid":"87706bdb-a705-44f5-bd9e-8a6446959962","_cell_guid":"d54bec1d-283c-4244-9c9d-f1fa722cbb41","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:04.091029Z","iopub.execute_input":"2024-07-21T17:01:04.091875Z","iopub.status.idle":"2024-07-21T17:01:08.824229Z","shell.execute_reply.started":"2024-07-21T17:01:04.091839Z","shell.execute_reply":"2024-07-21T17:01:08.823490Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"595fa3368c19455ca36251f6d78af457"}},"metadata":{}}]},{"cell_type":"code","source":"# This block of code is used to initialize Weights & Biases (wandb) for experiment tracking.\n\n# Retrieve the Weights & Biases API token from user secrets\nwandb_token = user_secrets.get_secret(\"WANDB_TOKEN\")\n\n# Import the wandb library for experiment tracking\nimport wandb\n\n# Log in to Weights & Biases using the retrieved API token\nwandb.login(key=wandb_token)\n\n# Initialize a new Weights & Biases run for tracking the experiment\nrun = wandb.init(\n    project='Training and tuning Phi-3-mini-4k-instruct for SQL | kaggle-sql-xp-phi-3-mini-4k-instruct.ipynb', \n    job_type=\"training\",  # Specify the type of job as training\n    anonymous=\"allow\"     # Allow anonymous logging if no user is logged in\n)","metadata":{"_uuid":"fc2f6ab2-9ace-4520-9f86-14dc166f3f48","_cell_guid":"e0da8460-21d8-4876-9578-55674bc69069","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:08.825632Z","iopub.execute_input":"2024-07-21T17:01:08.825921Z","iopub.status.idle":"2024-07-21T17:01:28.441132Z","shell.execute_reply.started":"2024-07-21T17:01:08.825895Z","shell.execute_reply":"2024-07-21T17:01:28.439245Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mspectrewolf8\u001b[0m (\u001b[33mspectrewolf8-cui\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240721_170111-3ih9amnm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/spectrewolf8-cui/Training%20and%20tuning%20Phi-3-mini-4k-instruct%20for%20SQL%20%7C%20kaggle-sql-xp-phi-3-mini-4k-instruct.ipynb/runs/3ih9amnm' target=\"_blank\">lilac-leaf-29</a></strong> to <a href='https://wandb.ai/spectrewolf8-cui/Training%20and%20tuning%20Phi-3-mini-4k-instruct%20for%20SQL%20%7C%20kaggle-sql-xp-phi-3-mini-4k-instruct.ipynb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/spectrewolf8-cui/Training%20and%20tuning%20Phi-3-mini-4k-instruct%20for%20SQL%20%7C%20kaggle-sql-xp-phi-3-mini-4k-instruct.ipynb' target=\"_blank\">https://wandb.ai/spectrewolf8-cui/Training%20and%20tuning%20Phi-3-mini-4k-instruct%20for%20SQL%20%7C%20kaggle-sql-xp-phi-3-mini-4k-instruct.ipynb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/spectrewolf8-cui/Training%20and%20tuning%20Phi-3-mini-4k-instruct%20for%20SQL%20%7C%20kaggle-sql-xp-phi-3-mini-4k-instruct.ipynb/runs/3ih9amnm' target=\"_blank\">https://wandb.ai/spectrewolf8-cui/Training%20and%20tuning%20Phi-3-mini-4k-instruct%20for%20SQL%20%7C%20kaggle-sql-xp-phi-3-mini-4k-instruct.ipynb/runs/3ih9amnm</a>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training model","metadata":{"_uuid":"1777d983-443e-42b4-81a3-5e72b1be975b","_cell_guid":"2f2d972c-a59b-41fe-aa6a-e191e4869dc9","trusted":true}},{"cell_type":"code","source":"# 'TrainingArguments' is a class from the Hugging Face Transformers library that provides hyperparameters for training.\n# 'output_dir=\"./results\"' sets the directory where the training results (like checkpoints and logs) will be saved.\n# 'num_train_epochs=1' sets the number of times the entire training dataset will be passed through the model.\n# 'per_device_train_batch_size=4' sets the batch size for training on each device (e.g., GPU).\n# 'gradient_accumulation_steps=1' sets the number of steps to accumulate gradients before performing a backward/update pass.\n# 'optim=\"paged_adamw_32bit\"' specifies the optimizer to use; in this case, \"paged_adamw_32bit\" is used.\n# 'save_steps=25' specifies the number of steps before saving a checkpoint.\n# 'logging_steps=10' specifies the number of steps before logging training metrics.\n# 'learning_rate=2e-4' sets the learning rate for the optimizer.\n# 'weight_decay=0.001' applies weight decay (L2 regularization) to prevent overfitting.\n# 'fp16=False' specifies whether to use 16-bit (half-precision) floating point.\n# 'bf16=False' specifies whether to use bfloat16 precision (an alternative to fp16).\n# 'max_grad_norm=0.3' clips the gradient norm to prevent the exploding gradient problem.\n# 'max_steps=-1' specifies the total number of training steps; -1 means no limit.\n# 'warmup_ratio=0.03' sets the proportion of training steps to perform learning rate warmup.\n# 'group_by_length=True' groups sequences of similar lengths together for efficient training.\n# 'lr_scheduler_type=\"constant\"' specifies the type of learning rate scheduler; in this case, it uses a constant learning rate.\n# 'report_to=\"wandb\"' specifies the reporting tool to use for logging; in this case, Weights and Biases (wandb) is used.\n\ntraining_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=2,#1 default\n    per_device_train_batch_size=4,#4 default\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=25,\n    logging_steps=5,#10 default but that's just for logging\n    learning_rate=2e-4,#1.41e-5 default\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,#False default\n    max_grad_norm=0.3,#0.3 default\n    max_steps=-1,\n    warmup_ratio=0.03,#0.03 default\n    group_by_length=True,\n    lr_scheduler_type=\"linear\",\n    report_to=\"wandb\"\n)","metadata":{"_uuid":"87479761-4a28-4a97-a683-e392dda7a580","_cell_guid":"1ab63e32-bf84-4aae-9f4a-88a54d842501","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:28.442853Z","iopub.execute_input":"2024-07-21T17:01:28.443249Z","iopub.status.idle":"2024-07-21T17:01:28.494573Z","shell.execute_reply.started":"2024-07-21T17:01:28.443209Z","shell.execute_reply":"2024-07-21T17:01:28.493389Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# 'SFTTrainer' is a class that provides a trainer for fine-tuning a model.\n# 'trainer' is a variable that holds the trainer.\n# 'model=model' is a parameter that sets the model to be trained to be 'model'.\n# 'train_dataset=synthetic_extracted_train_dataset' is a parameter that sets the training dataset to be 'synthetic_extracted_train_dataset'.\n# 'eval_dataset=synthetic_extracted_test_dataset' is a parameter that sets the evaluation dataset to be 'synthetic_extracted_test_dataset'.\n# 'peft_config=peft_config' is a parameter that sets the configuration for the Lora layer to be 'peft_config'.\n# 'dataset_text_field=\"text\"' is a parameter that sets the field in the dataset that contains the text to be 'text'.\n# 'max_seq_length=512' is a parameter that sets the maximum sequence length for the model to be 512.\n# 'tokenizer=tokenizer' is a parameter that sets the tokenizer to be 'tokenizer'.\n# 'args=args' is a parameter that sets the training arguments to be 'args'.\n# This line of code is used to create a trainer for fine-tuning the model with the specified parameters.\n\ntrainer = SFTTrainer(\n        model=model,\n        train_dataset=synthetic_extracted_train_dataset,\n        eval_dataset=synthetic_extracted_test_dataset,\n        peft_config=peft_config,\n        dataset_text_field=\"text\",\n        max_seq_length=512, #512 default\n        tokenizer=tokenizer,\n        args=training_arguments,\n)","metadata":{"_uuid":"31c3e042-bd30-4270-9a8f-7736a3cc43da","_cell_guid":"22a2ccf6-c9ca-4dd8-bf81-474daadccf12","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:28.496385Z","iopub.execute_input":"2024-07-21T17:01:28.496749Z","iopub.status.idle":"2024-07-21T17:01:32.035582Z","shell.execute_reply.started":"2024-07-21T17:01:28.496712Z","shell.execute_reply":"2024-07-21T17:01:32.034498Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4171345c1224d36820a37ceb39233c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a60d9c0b87f445ebd72fa23585f553e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# 'trainer.train()' is a method that starts the training of the model. It uses the training dataset, model, and training arguments that were specified when the trainer was created.\n\n# train the model\ntrainer.train()","metadata":{"_uuid":"ab70d953-c592-4c4f-b0cd-b19b96402bdb","_cell_guid":"c6bc6026-4ca3-4823-bac4-4846fe336733","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:01:32.036931Z","iopub.execute_input":"2024-07-21T17:01:32.037242Z","iopub.status.idle":"2024-07-21T17:06:09.713403Z","shell.execute_reply.started":"2024-07-21T17:01:32.037212Z","shell.execute_reply":"2024-07-21T17:06:09.711510Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='19' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  19/2500 04:06 < 9:59:36, 0.07 it/s, Epoch 0.01/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>0.847200</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.999300</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.032400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# 'trainer.save_model()' is a method that saves the trained model to the local file system. The model will be saved in the output directory that was specified in the training arguments.\n# This block of code is used to train the model and then save the trained model to the local file system.\n\n# save model locally\ntrainer.save_model()\ntokenizer.save_pretrained(\"./results\")","metadata":{"_uuid":"3ed6f9c4-aed8-4fa5-bc92-25116218c159","_cell_guid":"51dcb105-cebd-485a-be28-8a9f161f1fcd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.714565Z","iopub.status.idle":"2024-07-21T17:06:09.715083Z","shell.execute_reply.started":"2024-07-21T17:06:09.714824Z","shell.execute_reply":"2024-07-21T17:06:09.714848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.save_model(\"./path_to_save_model\")  # Save the model locally to specified directory\n# tokenizer.save_pretrained(\"./path_to_save_model\")  # Save the tokenizer to specified directory","metadata":{"_uuid":"bd666fd2-3d57-4e67-a085-4c6e39068359","_cell_guid":"e17a7304-5833-44c4-9f48-d0d6bc851984","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.716517Z","iopub.status.idle":"2024-07-21T17:06:09.716893Z","shell.execute_reply.started":"2024-07-21T17:06:09.716691Z","shell.execute_reply":"2024-07-21T17:06:09.716706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the repository name on the Hugging Face Hub where the model, trainer, and tokenizer will be pushed.\nhf_model_repo = \"spectrewolf8/sql-xp-phi-3-mini-4k\"\n\n# Push the trainer to the Hugging Face Hub.\n# This includes training arguments, optimizer states, and other relevant information.\ntrainer.push_to_hub(hf_model_repo)\n\n# Push the model to the Hugging Face Hub.\n# This saves the model weights and configuration to the specified repository.\ntrainer.model.push_to_hub(hf_model_repo)\n\n# Push the tokenizer to the Hugging Face Hub.\n# This saves the tokenizer configuration and vocab files to the specified repository.\ntokenizer.push_to_hub(hf_model_repo)","metadata":{"_uuid":"71364503-7745-423c-9d82-4998683fbe40","_cell_guid":"c02c9731-2790-49af-80a9-879c637cf42b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.718795Z","iopub.status.idle":"2024-07-21T17:06:09.719172Z","shell.execute_reply.started":"2024-07-21T17:06:09.719001Z","shell.execute_reply":"2024-07-21T17:06:09.719016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model stats","metadata":{"_uuid":"7ae767f7-6b10-445c-9667-8aaea5ac2a00","_cell_guid":"54aebe87-4764-4873-a420-35f60d82e1b1","trusted":true}},{"cell_type":"code","source":"# Finish the Weights & Biases (wandb) run.\n# This finalizes the current experiment run, ensuring all data is uploaded and the run is properly closed.\nwandb.finish()\n\n# Set the 'use_cache' configuration option of the model to True.\n# This enables caching of the computation results during inference, which can speed up the model's performance.\nmodel.config.use_cache = True\n\n# Set the model to evaluation mode.\n# This changes the model's behavior to inference mode, disabling features like dropout that are only used during training.\nmodel.eval()","metadata":{"_uuid":"032a4cbd-7eba-47d3-8bf1-d2265294d421","_cell_guid":"941f8584-d155-409b-ac04-261cb987867c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.722116Z","iopub.status.idle":"2024-07-21T17:06:09.722477Z","shell.execute_reply.started":"2024-07-21T17:06:09.722302Z","shell.execute_reply":"2024-07-21T17:06:09.722317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing model","metadata":{"_uuid":"e9711239-bc7b-44d1-a494-c1fd2493ec97","_cell_guid":"edc9daff-f2bc-4772-9d65-a89a27fd4f6c","trusted":true}},{"cell_type":"code","source":"# Create a text generation pipeline using the specified model and tokenizer.\n# The 'pipeline' function sets up a ready-to-use text generation pipeline, combining the model and tokenizer.\npipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)","metadata":{"_uuid":"5647df58-3917-4969-b987-e14e5c707f6d","_cell_guid":"ac22cd01-0504-4192-93ed-9b79037c4f05","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.723924Z","iopub.status.idle":"2024-07-21T17:06:09.724259Z","shell.execute_reply.started":"2024-07-21T17:06:09.724096Z","shell.execute_reply":"2024-07-21T17:06:09.724109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## example-1","metadata":{"_uuid":"721f18d3-a898-476d-9220-4ac5aa28932c","_cell_guid":"9ea5f6e3-8681-4a6b-8149-21dbbf679b59","trusted":true}},{"cell_type":"code","source":"# Define the input phrase which represents the user's request or query.\ninput_phrase = \"\"\"\ninsert 5 values\n\"\"\"\n\n# Define the context phrase which provides the SQL table schema relevant to the input phrase.\ncontext_phrase = \"\"\"\nCREATE TABLE tasks (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    name VARCHAR(100) NOT NULL,\n    task_name VARCHAR(100) NOT NULL,\n    userid INT NOT NULL,\n    date DATE NOT NULL,\n    FOREIGN KEY (userid) REFERENCES users(id)\n);\n\"\"\"\n\n# Create a prompt by applying a chat template to the input and context phrases using the tokenizer.\n# The 'apply_chat_template' method formats the input as a chat message, making it suitable for text generation.\n# 'tokenize=False' indicates that the input should not be tokenized yet.\n# 'add_generation_prompt=True' adds a prompt for text generation.\nprompt = pipe.tokenizer.apply_chat_template(\n    [{\"role\": \"user\", \"content\": f\"\\n #prompt: {input_phrase}\\n #context: {context_phrase}\"}],\n    tokenize=False,\n    add_generation_prompt=True\n)\n\n# Generate text using the pipeline with the specified parameters.\n# 'max_new_tokens=256' sets the maximum number of new tokens to generate.\n# 'do_sample=True' enables sampling for text generation.\n# 'num_beams=1' specifies the number of beams for beam search (1 means no beam search).\n# 'temperature=0.3' controls the randomness of predictions by scaling the logits before applying softmax.\n# 'top_k=50' considers only the top 50 token predictions for sampling.\n# 'top_p=0.95' enables nucleus sampling, considering tokens that have a cumulative probability of 0.95.\n# 'max_time=180' sets the maximum generation time to 180 seconds.\noutputs = pipe(\n    prompt,\n    max_new_tokens=256,\n    do_sample=True,\n    num_beams=1,\n    temperature=0.3,\n    top_k=50,\n    top_p=0.95,\n    max_time=180\n)\n\n# Print the generated text by stripping out the prompt portion and displaying only the new generated content.\nprint(outputs[0]['generated_text'][len(prompt):].strip())","metadata":{"_uuid":"d1d19218-0f5a-4a49-a702-6b13ff4c5292","_cell_guid":"3d1202a6-4e9d-459e-aa1a-dd5cb2e623ea","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.726745Z","iopub.status.idle":"2024-07-21T17:06:09.727220Z","shell.execute_reply.started":"2024-07-21T17:06:09.726979Z","shell.execute_reply":"2024-07-21T17:06:09.727000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## example-2","metadata":{"_uuid":"fe67186a-d567-4863-b3de-5f45b9fd7e78","_cell_guid":"01f13aab-731e-4992-8851-10b9f3c6582b","trusted":true}},{"cell_type":"code","source":"# Define a list of input phrases representing various SQL operations.\ninput_phrases = [\n    \"insert 5 values\",\n    \"select all records\",\n    \"update record with id 3\",\n    \"delete all records where task_name is 'coding'\",\n    \"add a new column 'status' to the table\",\n    \"find all tasks with userid 2\",\n    \"count the number of tasks per user\",\n    \"list all tasks sorted by date\",\n    \"join tasks with users\",\n    \"find the average number of tasks per user\"\n]\n\n# Define a list of context phrases which provide the SQL table schema.\n# The same context is used for all input phrases in this example.\ncontext_phrases = [\n    \"\"\"\n    CREATE TABLE tasks (\n        id INT AUTO_INCREMENT PRIMARY KEY,\n        name VARCHAR(100) NOT NULL,\n        task_name VARCHAR(100) NOT NULL,\n        userid INT NOT NULL,\n        date DATE NOT NULL,\n        FOREIGN KEY (userid) REFERENCES users(id)\n    );\n    \"\"\"\n] * len(input_phrases)  # Repeat the same context for all input phrases.\n\n# Apply the chat template to create prompts by combining input and context phrases.\n# The 'apply_chat_template' method formats each input phrase with its corresponding context phrase.\n# f\"\\n #prompt: {input_phrase}\\n #context: {context_phrase}\"\n\nprompts = [pipe.tokenizer.apply_chat_template(\n    [{\"role\": \"user\", \"content\": f\"\\n #prompt: {input_phrase}\\n #context: {context_phrase}\"}], \n    tokenize=False, \n    add_generation_prompt=True\n) for input_phrase, context_phrase in zip(input_phrases, context_phrases)]\n\n# Generate SQL queries using the text generation pipeline with specified parameters.\n# Each prompt is passed through the pipeline to generate the corresponding SQL query.\noutputs = [pipe(\n    prompt, \n    max_new_tokens=256, \n    do_sample=True, \n    num_beams=1, \n    temperature=0.3, \n    top_k=50, \n    top_p=0.95, \n    max_time=180\n) for prompt in prompts]\n\n# Print the results of the generated SQL queries.\n# For each generated output, strip out the prompt portion and display only the new generated content.\nfor i, output in enumerate(outputs):\n    generated_text = output[0]['generated_text'][len(prompts[i]):].strip()\n    print(f\"Prompt {i+1}:\")\n    print(generated_text)\n    print(\"\\n\")","metadata":{"_uuid":"d903567e-38ac-462f-8b3a-272fb67dc034","_cell_guid":"571a74b6-309b-4bb8-9dd7-8cba97ec73c6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.728941Z","iopub.status.idle":"2024-07-21T17:06:09.729264Z","shell.execute_reply.started":"2024-07-21T17:06:09.729104Z","shell.execute_reply":"2024-07-21T17:06:09.729118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading model from hugging face","metadata":{"_uuid":"67e85d38-4967-46bd-a496-90a917656249","_cell_guid":"84c83b01-4139-4968-b91a-a47a319a2c47","trusted":true}},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n\n# Set the seed for the random number generator to ensure reproducibility\nset_seed(1234)\n\n# Define the repository name for the Hugging Face model\n# 'hf_model_repo' is a variable that holds the repository name for the Hugging Face model\n# 'username/modelname' is the repository name, where 'username' is the username of the repository owner\n# and 'modelname' is the name of the model\nhf_model_repo = \"spectrewolf8/sql-xp-phi-3-mini-4k\"\n\n# Retrieve the device mapping and computation data type\n# 'device_map' is a variable that holds the mapping of the devices that are used for computation\n# 'compute_dtype' is a variable that holds the data type that is used for computation\n\n# device_map = {\"\": 0}\n# compute_dtype = torch.bfloat16 or torch.float16\ndevice_map, compute_dtype\n\n# Load a pre-trained tokenizer from the Hugging Face Model Hub\n# 'tokenizer' is the variable that holds the tokenizer\n# 'trust_remote_code=True' allows the execution of code from the model file\ntokenizer = AutoTokenizer.from_pretrained(hf_model_repo, trust_remote_code=True)\n\n# Load a pre-trained model for causal language modeling from the Hugging Face Model Hub\n# 'model' is the variable that holds the model\n# 'trust_remote_code=True' allows the execution of code from the model file\n# 'torch_dtype=compute_dtype' sets the data type for the PyTorch tensors\n# 'device_map=device_map' sets the device mapping\nmodel = AutoModelForCausalLM.from_pretrained(hf_model_repo, trust_remote_code=True, torch_dtype=compute_dtype, device_map=device_map)","metadata":{"_uuid":"2cf9c76a-1225-4514-a8da-4397500bf364","_cell_guid":"0f3e55fa-cbd9-4e7b-a11b-399ee368c8e5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.732985Z","iopub.status.idle":"2024-07-21T17:06:09.733326Z","shell.execute_reply.started":"2024-07-21T17:06:09.733155Z","shell.execute_reply":"2024-07-21T17:06:09.733170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)","metadata":{"_uuid":"08031757-fe3d-4ddd-9aaa-4b731ff3dc88","_cell_guid":"e14a8cfd-387a-411c-9a8f-45a89bf631f2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.734381Z","iopub.status.idle":"2024-07-21T17:06:09.734692Z","shell.execute_reply.started":"2024-07-21T17:06:09.734538Z","shell.execute_reply":"2024-07-21T17:06:09.734552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rest of the steps from here are the same as example-1 and example-2","metadata":{"_uuid":"c9234054-fe16-45ed-803a-58301c68bfac","_cell_guid":"155c04bd-9753-4574-b283-5b209ee972ca","trusted":true}},{"cell_type":"code","source":"# Define the context and input phrase\ncontext_phrase = \"\"\"\nCREATE TABLE users (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    username VARCHAR(50) NOT NULL,\n    email VARCHAR(100) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE projects (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    project_name VARCHAR(100) NOT NULL,\n    description TEXT,\n    start_date DATE NOT NULL,\n    end_date DATE,\n    user_id INT,\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n\nCREATE TABLE tasks (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    task_name VARCHAR(100) NOT NULL,\n    status VARCHAR(20) CHECK (status IN ('pending', 'in_progress', 'completed')),\n    priority INT CHECK (priority BETWEEN 1 AND 5),\n    project_id INT,\n    assigned_to INT,\n    due_date DATE,\n    FOREIGN KEY (project_id) REFERENCES projects(id),\n    FOREIGN KEY (assigned_to) REFERENCES users(id)\n);\n\nCREATE TABLE comments (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    task_id INT,\n    user_id INT,\n    comment_text TEXT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (task_id) REFERENCES tasks(id),\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n\"\"\"\n\ninput_phrase = \"\"\"\nUpdate the status of tasks to 'completed' for all tasks that have passed their due date. Also, update the end date of the corresponding projects to the current date if all tasks in the project are completed.\n\"\"\"\n\n# Apply the chat template to create the prompt\nprompt = pipe.tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": f\"\\n #prompt: {input_phrase}\\n #context: {context_phrase}\"}], tokenize=False, add_generation_prompt=True)\n\n# Generate SQL query\noutputs = pipe(prompt, max_new_tokens=256, do_sample=True, num_beams=1, temperature=0.3, top_k=50, top_p=0.95, max_time=180)\n\n# Print the result\ngenerated_text = outputs[0]['generated_text'][len(prompt):].strip()\nprint(f\"Generated SQL Query:\\n{generated_text}\")","metadata":{"_uuid":"9fab445a-afb9-416e-b6c5-518d9ca00d21","_cell_guid":"292d94f0-0dc6-40e7-a332-8525518d32e4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.736773Z","iopub.status.idle":"2024-07-21T17:06:09.737151Z","shell.execute_reply.started":"2024-07-21T17:06:09.736984Z","shell.execute_reply":"2024-07-21T17:06:09.737000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(prompt)","metadata":{"_uuid":"20750dd7-73e7-41dd-a6c3-3d2b4c15f7ff","_cell_guid":"0a581f15-ce93-4dcb-8ca3-e07aed60580d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-21T17:06:09.739689Z","iopub.status.idle":"2024-07-21T17:06:09.740045Z","shell.execute_reply.started":"2024-07-21T17:06:09.739875Z","shell.execute_reply":"2024-07-21T17:06:09.739890Z"},"trusted":true},"execution_count":null,"outputs":[]}]}